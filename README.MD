# Route Crawler

![Interface](images/Capture.PNG)

Route Crawler is a CLI application built with Node.js that scans a given website and displays all the routes found on it. It utilizes modern web technologies such as axios for making HTTP requests and jsdom for parsing HTML, effectively extracting and listing all hyperlinks present on a webpage.

## Features

- Scans a given website for all routes.
- Handles dynamic routes and JavaScript-driven navigation.
- Outputs the total number of routes found.
- Provides a list of all discovered routes.

## Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/RizkyZaki/route-crawler.git
   cd route-crawler
   ```

2. Install the required dependencies:

   ```bash
   npm i
   ```

## Usage

Run the main script:

```bash
npm start crawl
```
